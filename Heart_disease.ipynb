{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345\n",
    "\n",
    "#Manipulate data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Scale and split data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Easier to read\n",
    "from pprint import pprint\n",
    "\n",
    "#Draw ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Heart_disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'target':'outcome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  outcome  \n",
       "0   0     1        1  \n",
       "1   0     2        1  \n",
       "2   0     2        1  \n",
       "3   0     2        1  \n",
       "4   0     2        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:\n",
      "1 138\n",
      "0 165\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['outcome'] == 0:\n",
    "        one+=1\n",
    "    else:\n",
    "        zero+=1\n",
    "        \n",
    "print(\"Class balance:\")\n",
    "print(\"1\",one)\n",
    "print(\"0\",zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal     outcome  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "sex          96\n",
       "cp          143\n",
       "trestbps      0\n",
       "chol          0\n",
       "fbs         258\n",
       "restecg     147\n",
       "thalach       0\n",
       "exang       204\n",
       "oldpeak      99\n",
       "slope        21\n",
       "ca          175\n",
       "thal          2\n",
       "outcome     138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df==0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  outcome   303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate x and y and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('outcome', axis=1)\n",
    "y = df['outcome']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "First Round: {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "Second Round: {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "svmparam = SVC()\n",
    "X_svc_train, X_svc_test, y_svc_train, y_svc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'C': [0.01,0.1,1,10,100], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'C': [0.8,0.9,1.0,1.1,1.2], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"First Round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round\n",
    "param_grid = {'C': [0.8, 0.9,1,1.1, 1.2], 'gamma': [0.008, 0.009, 0.01, 0.02, 0.03],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Second Round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8681318681318682\n",
      "Recall: 0.9166666666666666\n",
      "Precision 0.8461538461538461\n",
      "F1_Score: 0.8799999999999999\n",
      "AUC: 0.9229651162790697\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[35  8]\n",
      " [ 4 44]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#svc = SVC(probability=True)\n",
    "\n",
    "#Accuracy 0.8351648351648352\n",
    "#Recall: 0.875\n",
    "#Precision 0.8235294117647058\n",
    "#F1_Score: 0.8484848484848485\n",
    "#AUC: 0.9060077519379846\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[34  9]\n",
    "# [ 6 42]]\n",
    "\n",
    "#With Hyperparametering\n",
    "svc = SVC(probability=True, C=1, gamma=0.01, kernel='sigmoid')\n",
    "\n",
    "svc.fit(X_svc_train, y_svc_train)\n",
    "y_svc_pred = svc.predict(X_svc_test)\n",
    "\n",
    "svc_score = svc.predict_proba(X_svc_test)[: ,1]\n",
    "\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "\n",
    "accuracy_score_svc = accuracy_score(y_svc_test, y_svc_pred)\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "auc_svc = roc_auc_score(y_svc_test, svc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_svc)\n",
    "print(\"Recall:\", recall_score_svc)\n",
    "print(\"Precision\", precision_score_svc)\n",
    "print(\"F1_Score:\", f1_score_svc)\n",
    "print(\"AUC:\", auc_svc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_svc_test, y_svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "dctparam = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "X_dtc_train, X_dtc_test, y_dtc_train, y_dtc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [None, 1,2,3,4], 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1,2,3,4,5], 'criterion' : ['gini', 'entropy'], 'min_samples_split' : [1,2,3,4,5]}\n",
    "grid_search = GridSearchCV(estimator = dctparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_dtc_train, y_dtc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7582417582417582\n",
      "Recall: 0.8333333333333334\n",
      "Precision 0.7407407407407407\n",
      "F1_Score: 0.7843137254901961\n",
      "AUC: 0.7674418604651163\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[29 14]\n",
      " [ 8 40]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#dtc = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.7692307692307693\n",
    "#Recall: 0.75\n",
    "#Precision 0.8\n",
    "#F1_Score: 0.7741935483870969\n",
    "#AUC: 0.7703488372093024\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[34  9]\n",
    "# [12 36]]\n",
    "\n",
    "#With Hyperparametering\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = RANDOM_STATE, max_depth=None, max_features=None, criterion = 'entropy',\n",
    "                             min_samples_leaf=3, min_samples_split=2)\n",
    "\n",
    "dtc.fit(X_dtc_train,y_dtc_train)\n",
    "y_dtc_pred = dtc.predict(X_dtc_test)\n",
    "\n",
    "dtc_score = dtc.predict_proba(X_dtc_test)[: , 1]\n",
    "\n",
    "accuracy_score_dtc = accuracy_score(y_dtc_test, y_dtc_pred)\n",
    "recall_score_dtc = recall_score(y_dtc_test, y_dtc_pred)\n",
    "precision_score_dtc = precision_score(y_dtc_test, y_dtc_pred)\n",
    "f1_score_dtc = f1_score(y_dtc_test, y_dtc_pred)\n",
    "auc_dtc = roc_auc_score(y_dtc_test, dtc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_dtc)\n",
    "print(\"Recall:\", recall_score_dtc)\n",
    "print(\"Precision\", precision_score_dtc)\n",
    "print(\"F1_Score:\", f1_score_dtc)\n",
    "print(\"AUC:\", auc_dtc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_dtc_test, y_dtc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 0.1, 'max_iter': 250, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "First round: {'C': 0.08, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Second round: {'C': 0.05, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Third round: {'C': 0.05, 'max_iter': 15, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "lrparam = LogisticRegression()\n",
    "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "              'max_iter' : [250, 500, 1000, 1250, 1500], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.08, 0.09, 0.1, 0.2, 0.3], \n",
    "              'max_iter' : [50,100,150,200,250], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.04,0.05,0.06,0.07,0.08], \n",
    "              'max_iter' : [50,100,150,200,250], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.04,0.05,0.06,0.07,0.08], \n",
    "              'max_iter' : [15,20,30,40,50], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Third round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8461538461538461\n",
      "Recall: 0.8958333333333334\n",
      "Precision 0.8269230769230769\n",
      "F1_Score: 0.86\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[34  9]\n",
      " [ 5 43]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#lr = LogisticRegression()\n",
    "\n",
    "#Accuracy 0.8021978021978022\n",
    "#Recall: 0.7916666666666666\n",
    "#Precision 0.8260869565217391\n",
    "#F1_Score: 0.8085106382978724\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[35  8]\n",
    "# [10 38]]\n",
    "\n",
    "#With Hyperparametering\n",
    "#Trying a new level for C (0.01, which gave a better result than 0.05)\n",
    "lr = LogisticRegression(C = 0.01, max_iter = 15, penalty = 'l2', solver = 'newton-cg')\n",
    "\n",
    "lr.fit(X_lr_train,y_lr_train)\n",
    "y_lr_pred = lr.predict(X_lr_test)\n",
    "\n",
    "accuracy_score_lr = accuracy_score(y_lr_test, y_lr_pred)\n",
    "recall_score_lr = recall_score(y_lr_test, y_lr_pred)\n",
    "precision_score_lr = precision_score(y_lr_test, y_lr_pred)\n",
    "f1_score_lr = f1_score(y_lr_test, y_lr_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_lr)\n",
    "print(\"Recall:\", recall_score_lr)\n",
    "print(\"Precision\", precision_score_lr)\n",
    "print(\"F1_Score:\", f1_score_lr)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_lr_test, y_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'algorithm': 'auto', 'n_neighbors': 8, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knnparam = KNeighborsClassifier()\n",
    "X_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_neighbors': [2,3,4,5,6,7,8,9,10], 'weights': ['distance', 'uniform'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}\n",
    "grid_search = GridSearchCV(estimator = knnparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_knn_train, y_knn_train)\n",
    "print( \"Initial:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8241758241758241\n",
      "Recall: 0.8125\n",
      "Precision 0.8478260869565217\n",
      "F1_Score: 0.8297872340425533\n",
      "AUC: 0.8936531007751938\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[36  7]\n",
      " [ 9 39]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#knn = KNeighborsClassifier()\n",
    "\n",
    "#Accuracy 0.8351648351648352\n",
    "#Recall: 0.8541666666666666\n",
    "#Precision 0.8367346938775511\n",
    "#F1_Score: 0.845360824742268\n",
    "#AUC: 0.8817829457364341\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[35  8]\n",
    "# [ 7 41]]\n",
    "\n",
    "#With Hyperparametering\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 8 , weights = 'uniform', algorithm = 'auto')\n",
    "\n",
    "knn.fit(X_knn_train,y_knn_train)\n",
    "y_knn_pred = knn.predict(X_knn_test)\n",
    "\n",
    "knn_score = knn.predict_proba(X_knn_test)[: , 1]\n",
    "\n",
    "accuracy_score_knn = accuracy_score(y_knn_test, y_knn_pred)\n",
    "recall_score_knn = recall_score(y_knn_test, y_knn_pred)\n",
    "precision_score_knn = precision_score(y_knn_test, y_knn_pred)\n",
    "f1_score_knn = f1_score(y_knn_test, y_knn_pred)\n",
    "auc_knn = roc_auc_score(y_knn_test, knn_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_knn)\n",
    "print(\"Recall:\", recall_score_knn)\n",
    "print(\"Precision\", precision_score_knn)\n",
    "print(\"F1_Score:\", f1_score_knn)\n",
    "print(\"AUC:\", auc_knn)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_knn_test, y_knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "First round: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 250}\n",
      "Second round: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "#Optimizing parameters\n",
    "\n",
    "rfparam = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [1, 2, 3, 4], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [1,2,3,4], 'n_estimators' : [25, 50, 100, 150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'max_depth': [3,4,5,6], 'min_samples_leaf': [1,2,3], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [1,2,3,4], 'n_estimators' : [100,150,200,250]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round\n",
    "param_grid = {'max_depth': [5,6,7,8], 'min_samples_leaf': [1,2], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [200,250,300,350]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Second round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8461538461538461\n",
      "Recall: 0.9166666666666666\n",
      "Precision 0.8148148148148148\n",
      "F1_Score: 0.8627450980392156\n",
      "AUC: 0.9152131782945736\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[33 10]\n",
      " [ 4 44]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "\n",
    "#rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.8021978021978022\n",
    "#Recall: 0.8333333333333334\n",
    "#Precision 0.8\n",
    "#F1_Score: 0.816326530612245\n",
    "#AUC: 0.8938953488372093\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[33 10]\n",
    "# [ 8 40]]\n",
    "\n",
    "#With Hyperparametering\n",
    "rf = RandomForestClassifier(n_estimators = 300, random_state=RANDOM_STATE, \n",
    "                            min_samples_leaf=1, min_samples_split=4, max_depth=7, criterion = 'gini')\n",
    "\n",
    "rf.fit(X_rf_train, y_rf_train)\n",
    "y_rf_pred = rf.predict(X_rf_test)\n",
    "\n",
    "rf_score = rf.predict_proba(X_rf_test)[: , 1]\n",
    "\n",
    "accuracy_score_rf = accuracy_score(y_rf_test, y_rf_pred)\n",
    "recall_score_rf = recall_score(y_rf_test, y_rf_pred)\n",
    "precision_score_rf = precision_score(y_rf_test, y_rf_pred)\n",
    "f1_score_rf = f1_score(y_rf_test, y_rf_pred)\n",
    "auc_rf = roc_auc_score(y_rf_test, rf_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_rf)\n",
    "print(\"Recall:\", recall_score_rf)\n",
    "print(\"Precision\", precision_score_rf)\n",
    "print(\"F1_Score:\", f1_score_rf)\n",
    "print(\"AUC:\", auc_rf)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_rf_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'learning_rate': 0.1, 'n_estimators': 250}\n",
      "First round: {'learning_rate': 0.1, 'n_estimators': 250}\n",
      "Second round: {'learning_rate': 0.08, 'n_estimators': 200}\n",
      "Third round: {'learning_rate': 0.07, 'n_estimators': 250}\n",
      "Fourth round: {'learning_rate': 0.07, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "abparam = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "X_ab_train, X_ab_test, y_ab_train, y_ab_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_estimators': [50, 100, 150, 200, 250], 'learning_rate': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round optimizing\n",
    "param_grid = {'n_estimators': [150, 200, 250, 300, 350], 'learning_rate': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round optimizing\n",
    "param_grid = {'n_estimators': [150, 200, 250, 300, 350], 'learning_rate': [0.08, 0.09, 0.1, 0.2, 0.3]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd Round optimizing\n",
    "param_grid = {'n_estimators': [100, 150, 200, 250, 300], 'learning_rate': [0.06, 0.07, 0.08, 0.09, 0.1]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Third round:\", grid_search.best_params_)\n",
    "\n",
    "#4th Round optimizing\n",
    "param_grid = {'n_estimators': [150, 200, 250, 300, 350], 'learning_rate': [0.05,0.06, 0.07, 0.08, 0.09]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Fourth round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8241758241758241\n",
      "Recall: 0.8333333333333334\n",
      "Precision 0.8333333333333334\n",
      "F1_Score: 0.8333333333333334\n",
      "AUC: 0.8832364341085271\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[35  8]\n",
      " [ 8 40]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#ab = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.7912087912087912\n",
    "#Recall: 0.8125\n",
    "#Precision 0.7959183673469388\n",
    "#F1_Score: 0.8041237113402061\n",
    "#AUC: 0.8250968992248062\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[33 10]\n",
    "# [ 9 39]]\n",
    "\n",
    "#With Hyperparametering\n",
    "ab = AdaBoostClassifier(n_estimators=250, learning_rate=0.07, random_state=RANDOM_STATE)\n",
    "\n",
    "ab.fit(X_ab_train, y_ab_train)\n",
    "y_ab_pred = ab.predict(X_ab_test)\n",
    "\n",
    "ab_score = ab.predict_proba(X_ab_test)[: , 1]\n",
    "\n",
    "accuracy_score_ab = accuracy_score(y_ab_test, y_ab_pred)\n",
    "recall_score_ab = recall_score(y_ab_test, y_ab_pred)\n",
    "precision_score_ab = precision_score(y_ab_test, y_ab_pred)\n",
    "f1_score_ab = f1_score(y_ab_test, y_ab_pred)\n",
    "auc_ab = roc_auc_score(y_ab_test, ab_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_ab)\n",
    "print(\"Recall:\", recall_score_ab)\n",
    "print(\"Precision\", precision_score_ab)\n",
    "print(\"F1_Score:\", f1_score_ab)\n",
    "print(\"AUC:\", auc_ab)\n",
    "print()\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_ab_test, y_ab_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
