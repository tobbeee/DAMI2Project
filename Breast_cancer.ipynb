{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345\n",
    "\n",
    "#Manipulate data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Scale and split data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Easier to read\n",
    "from pprint import pprint\n",
    "\n",
    "#Draw ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'diagnosis':'outcome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id outcome  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302       M        17.99         10.38          122.80     1001.0   \n",
       "1    842517       M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903       M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301       M        11.42         20.38           77.58      386.1   \n",
       "4  84358402       M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"outcome\"].replace({\"M\": 1, \"B\": 0}, inplace=True)\n",
    "df[\"outcome\"] = df[\"outcome\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  outcome  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        1        17.99         10.38          122.80     1001.0   \n",
       "1    842517        1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        1        11.42         20.38           77.58      386.1   \n",
       "4  84358402        1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:\n",
      "1 212\n",
      "0 357\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['outcome'] == 1:\n",
    "        one+=1\n",
    "    else:\n",
    "        zero+=1\n",
    "\n",
    "print(\"Class balance:\")\n",
    "print(\"1\",one)\n",
    "print(\"0\",zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id', axis=1)\n",
    "df = df.drop('Unnamed: 32', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          outcome  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome                    357\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean              13\n",
       "concave points_mean         13\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                13\n",
       "concave points_se           13\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst             13\n",
       "concave points_worst        13\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df==0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   outcome                  569 non-null    int32  \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate x and y and scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('outcome', axis=1)\n",
    "y = df['outcome']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "First round: {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "Second Round: {'C': 12, 'gamma': 0.008, 'kernel': 'sigmoid'}\n",
      "Third Round: {'C': 12, 'gamma': 0.008, 'kernel': 'sigmoid'}\n",
      "Fourth Round: {'C': 12, 'gamma': 0.008, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "svmparam = SVC()\n",
    "\n",
    "#Random values initial\n",
    "X_svc_train, X_svc_test, y_svc_train, y_svc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "param_grid = {'C': [0.01,0.1,1,10,100], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round optimizing\n",
    "param_grid = {'C': [8,9,10,11,12], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round optimizing\n",
    "param_grid = {'C': [8,9,10,11,12], 'gamma': [0.008, 0.009, 0.01, 0.02, 0.03],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Second Round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd Round optimizing\n",
    "param_grid = {'C': [10,11,12,13,14], 'gamma': [0.008, 0.009, 0.01, 0.02, 0.03],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Third Round:\", grid_search.best_params_)\n",
    "\n",
    "#4th Round optimizing\n",
    "param_grid = {'C': [10,11,12,13,14], 'gamma': [0.006, 0.007, 0.008, 0.009, 0.01],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Fourth Round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9766081871345029\n",
      "Recall: 0.9333333333333333\n",
      "Precision 1.0\n",
      "F1_Score: 0.9655172413793104\n",
      "AUC: 0.9912912912912912\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[111   0]\n",
      " [  4  56]]\n"
     ]
    }
   ],
   "source": [
    "#Without hyperparametering\n",
    "#svc = SVC(probability=True)\n",
    "\n",
    "#Accuracy 0.9649122807017544\n",
    "#Recall: 0.95\n",
    "#Precision 0.95\n",
    "#F1_Score: 0.9500000000000001\n",
    "#AUC: 0.9926426426426426\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[108   3]\n",
    "# [  3  57]]\n",
    "\n",
    "#With hyperparametering\n",
    "svc = SVC(probability=True, C=12, gamma=0.008, kernel='sigmoid')\n",
    "\n",
    "svc.fit(X_svc_train, y_svc_train)\n",
    "y_svc_pred = svc.predict(X_svc_test)\n",
    "\n",
    "svc_score = svc.predict_proba(X_svc_test)[: ,1]\n",
    "\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "\n",
    "accuracy_score_svc = accuracy_score(y_svc_test, y_svc_pred)\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "auc_svc = roc_auc_score(y_svc_test, svc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_svc)\n",
    "print(\"Recall:\", recall_score_svc)\n",
    "print(\"Precision\", precision_score_svc)\n",
    "print(\"F1_Score:\", f1_score_svc)\n",
    "print(\"AUC:\", auc_svc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_svc_test, y_svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "First round: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "dctparam = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "X_dtc_train, X_dtc_test, y_dtc_train, y_dtc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [None, 1,2,3,4], 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1,2,3,4,5], 'criterion' : ['gini', 'entropy'], 'min_samples_split' : [1,2,3,4,5]}\n",
    "grid_search = GridSearchCV(estimator = dctparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_dtc_train, y_dtc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#First round\n",
    "param_grid = {'max_depth': [2,3,4,5,6], 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1,2,3,4,5], 'criterion' : ['gini', 'entropy'], 'min_samples_split' : [1,2,3,4]}\n",
    "grid_search = GridSearchCV(estimator = dctparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_dtc_train, y_dtc_train)\n",
    "print( \"First round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.935672514619883\n",
      "Recall: 0.9166666666666666\n",
      "Precision 0.9016393442622951\n",
      "F1_Score: 0.9090909090909091\n",
      "AUC: 0.9413663663663663\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[105   6]\n",
      " [  5  55]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "\n",
    "#dtc = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.8888888888888888\n",
    "#Recall: 0.9166666666666666\n",
    "#Precision 0.7971014492753623\n",
    "#F1_Score: 0.8527131782945736\n",
    "#AUC: 0.8952702702702702\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[97 14]\n",
    "# [ 5 55]]\n",
    "\n",
    "#With Hyperparametering\n",
    "dtc = DecisionTreeClassifier(random_state = RANDOM_STATE, max_depth=4, max_features='log2', criterion = 'entropy',\n",
    "                             min_samples_leaf=3, min_samples_split=2)\n",
    "\n",
    "dtc.fit(X_dtc_train,y_dtc_train)\n",
    "y_dtc_pred = dtc.predict(X_dtc_test)\n",
    "\n",
    "dtc_score = dtc.predict_proba(X_dtc_test)[: , 1]\n",
    "\n",
    "accuracy_score_dtc = accuracy_score(y_dtc_test, y_dtc_pred)\n",
    "recall_score_dtc = recall_score(y_dtc_test, y_dtc_pred)\n",
    "precision_score_dtc = precision_score(y_dtc_test, y_dtc_pred)\n",
    "f1_score_dtc = f1_score(y_dtc_test, y_dtc_pred)\n",
    "auc_dtc = roc_auc_score(y_dtc_test, dtc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_dtc)\n",
    "print(\"Recall:\", recall_score_dtc)\n",
    "print(\"Precision\", precision_score_dtc)\n",
    "print(\"F1_Score:\", f1_score_dtc)\n",
    "print(\"AUC:\", auc_dtc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_dtc_test, y_dtc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "First round: {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Second round: {'C': 0.75, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Third round: {'C': 0.75, 'max_iter': 30, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Fourth round: {'C': 0.75, 'max_iter': 25, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Fifth round: {'C': 0.75, 'max_iter': 20, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Sixth round: {'C': 0.75, 'max_iter': 15, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "lrparam = LogisticRegression()\n",
    "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "              'max_iter' : [250, 500, 1000, 1250, 1500], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "              'max_iter' : [50,100,150,200,250], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.5, 0.75, 1, 1.25, 1.5], \n",
    "              'max_iter' : [50,100,150,200,250], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.5, 0.75, 1, 1.25, 1.5], \n",
    "              'max_iter' : [30,40,50], 'solver' : ['newton-cg']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Third round:\", grid_search.best_params_)\n",
    "\n",
    "#4th round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.5, 0.75, 1, 1.25, 1.5], \n",
    "              'max_iter' : [25,30,35], 'solver' : ['newton-cg']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Fourth round:\", grid_search.best_params_)\n",
    "\n",
    "#5th round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.5, 0.75, 1], \n",
    "              'max_iter' : [20,25,30], 'solver' : ['newton-cg']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Fifth round:\", grid_search.best_params_)\n",
    "\n",
    "#6th round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.5, 0.75, 1], \n",
    "              'max_iter' : [15,20,25], 'solver' : ['newton-cg']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Sixth round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9824561403508771\n",
      "Recall: 0.95\n",
      "Precision 1.0\n",
      "F1_Score: 0.9743589743589743\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[111   0]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#lr = LogisticRegression()\n",
    "\n",
    "#Accuracy 0.8021978021978022\n",
    "#Recall: 0.7916666666666666\n",
    "#Precision 0.8260869565217391\n",
    "#F1_Score: 0.8085106382978724\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[35  8]\n",
    "# [10 38]]\n",
    "\n",
    "#With Hyperparametering\n",
    "#Trying a new level for C (0.5, which gave a better result than 0.75)\n",
    "lr = LogisticRegression(C = 0.5, max_iter = 15, penalty = 'l2', solver = 'newton-cg')\n",
    "\n",
    "lr.fit(X_lr_train,y_lr_train)\n",
    "y_lr_pred = lr.predict(X_lr_test)\n",
    "\n",
    "accuracy_score_lr = accuracy_score(y_lr_test, y_lr_pred)\n",
    "recall_score_lr = recall_score(y_lr_test, y_lr_pred)\n",
    "precision_score_lr = precision_score(y_lr_test, y_lr_pred)\n",
    "f1_score_lr = f1_score(y_lr_test, y_lr_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_lr)\n",
    "print(\"Recall:\", recall_score_lr)\n",
    "print(\"Precision\", precision_score_lr)\n",
    "print(\"F1_Score:\", f1_score_lr)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_lr_test, y_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'algorithm': 'auto', 'n_neighbors': 8, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knnparam = KNeighborsClassifier()\n",
    "X_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_neighbors': [2,3,4,5,6,7,8,9,10], 'weights': ['distance', 'uniform'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}\n",
    "grid_search = GridSearchCV(estimator = knnparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_knn_train, y_knn_train)\n",
    "print( \"Initial:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9590643274853801\n",
      "Recall: 0.9\n",
      "Precision 0.9818181818181818\n",
      "F1_Score: 0.9391304347826087\n",
      "AUC: 0.9863363363363363\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[110   1]\n",
      " [  6  54]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#knn = KNeighborsClassifier()\n",
    "\n",
    "#Accuracy 0.9649122807017544\n",
    "#Recall: 0.9\n",
    "#Precision 1.0\n",
    "#F1_Score: 0.9473684210526316\n",
    "#AUC: 0.9856606606606606\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[111   0]\n",
    "# [  6  54]]\n",
    "\n",
    "#With Hyperparametering\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 8 , weights = 'distance', algorithm = 'auto')\n",
    "\n",
    "knn.fit(X_knn_train,y_knn_train)\n",
    "y_knn_pred = knn.predict(X_knn_test)\n",
    "\n",
    "knn_score = knn.predict_proba(X_knn_test)[: , 1]\n",
    "\n",
    "accuracy_score_knn = accuracy_score(y_knn_test, y_knn_pred)\n",
    "recall_score_knn = recall_score(y_knn_test, y_knn_pred)\n",
    "precision_score_knn = precision_score(y_knn_test, y_knn_pred)\n",
    "f1_score_knn = f1_score(y_knn_test, y_knn_pred)\n",
    "auc_knn = roc_auc_score(y_knn_test, knn_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_knn)\n",
    "print(\"Recall:\", recall_score_knn)\n",
    "print(\"Precision\", precision_score_knn)\n",
    "print(\"F1_Score:\", f1_score_knn)\n",
    "print(\"AUC:\", auc_knn)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_knn_test, y_knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 25}\n",
      "First round: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "#Optimizing parameters\n",
    "\n",
    "rfparam = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [1, 2, 3, 4], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [1,2,3,4], 'n_estimators' : [25, 50, 100, 150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'max_depth': [3,4,5], 'min_samples_leaf': [1,2], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [10,25,40]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"First round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9473684210526315\n",
      "Recall: 0.95\n",
      "Precision 0.9047619047619048\n",
      "F1_Score: 0.9268292682926829\n",
      "AUC: 0.9813813813813813\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[105   6]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.9473684210526315\n",
    "#Recall: 0.95\n",
    "#Precision 0.9047619047619048\n",
    "#F1_Score: 0.9268292682926829\n",
    "#AUC: 0.9765765765765764\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[105   6]\n",
    "# [  3  57]]\n",
    "\n",
    "#With Hyperparametering\n",
    "rf = RandomForestClassifier(n_estimators = 25, random_state=RANDOM_STATE, \n",
    "                           min_samples_leaf=1, min_samples_split=4, max_depth=4, criterion = 'gini')\n",
    "\n",
    "rf.fit(X_rf_train, y_rf_train)\n",
    "y_rf_pred = rf.predict(X_rf_test)\n",
    "\n",
    "rf_score = rf.predict_proba(X_rf_test)[: , 1]\n",
    "\n",
    "accuracy_score_rf = accuracy_score(y_rf_test, y_rf_pred)\n",
    "recall_score_rf = recall_score(y_rf_test, y_rf_pred)\n",
    "precision_score_rf = precision_score(y_rf_test, y_rf_pred)\n",
    "f1_score_rf = f1_score(y_rf_test, y_rf_pred)\n",
    "auc_rf = roc_auc_score(y_rf_test, rf_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_rf)\n",
    "print(\"Recall:\", recall_score_rf)\n",
    "print(\"Precision\", precision_score_rf)\n",
    "print(\"F1_Score:\", f1_score_rf)\n",
    "print(\"AUC:\", auc_rf)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_rf_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'learning_rate': 1, 'n_estimators': 250}\n",
      "First round: {'learning_rate': 1, 'n_estimators': 350}\n",
      "Second round: {'learning_rate': 0.8, 'n_estimators': 450}\n",
      "Third round: {'learning_rate': 0.8, 'n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "abparam = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "X_ab_train, X_ab_test, y_ab_train, y_ab_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_estimators': [50, 100, 150, 200, 250], 'learning_rate': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round optimizing\n",
    "param_grid = {'n_estimators': [150, 200, 250, 300, 350], 'learning_rate': [0.8,0.9,1,0,2.0,3.0]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round optimizing\n",
    "param_grid = {'n_estimators': [350,400,450,500,550], 'learning_rate': [0.8,0.9,1,0,2.0,3.0]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd Round optimizing\n",
    "param_grid = {'n_estimators': [350,400,450,500,550], 'learning_rate': [0.5,0.6,0.7,0.8,0.9]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Third round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9590643274853801\n",
      "Recall: 0.95\n",
      "Precision 0.9344262295081968\n",
      "F1_Score: 0.9421487603305784\n",
      "AUC: 0.98993993993994\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[107   4]\n",
      " [  3  57]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#ab = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.9590643274853801\n",
    "#Recall: 0.9333333333333333\n",
    "#Precision 0.9491525423728814\n",
    "#F1_Score: 0.9411764705882353\n",
    "#AUC: 0.9896396396396396\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[108   3]\n",
    "# [  4  56]]\n",
    "\n",
    "#With Hyperparametering\n",
    "ab = AdaBoostClassifier(n_estimators=450, learning_rate=0.8, random_state=RANDOM_STATE)\n",
    "\n",
    "ab.fit(X_ab_train, y_ab_train)\n",
    "y_ab_pred = ab.predict(X_ab_test)\n",
    "\n",
    "ab_score = ab.predict_proba(X_ab_test)[: , 1]\n",
    "\n",
    "accuracy_score_ab = accuracy_score(y_ab_test, y_ab_pred)\n",
    "recall_score_ab = recall_score(y_ab_test, y_ab_pred)\n",
    "precision_score_ab = precision_score(y_ab_test, y_ab_pred)\n",
    "f1_score_ab = f1_score(y_ab_test, y_ab_pred)\n",
    "auc_ab = roc_auc_score(y_ab_test, ab_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_ab)\n",
    "print(\"Recall:\", recall_score_ab)\n",
    "print(\"Precision\", precision_score_ab)\n",
    "print(\"F1_Score:\", f1_score_ab)\n",
    "print(\"AUC:\", auc_ab)\n",
    "print()\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_ab_test, y_ab_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
