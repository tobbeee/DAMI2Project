{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345\n",
    "\n",
    "#Manipulate data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Scale and split data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Easier to read\n",
    "from pprint import pprint\n",
    "\n",
    "#Draw ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Heart_disease_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  chest pain type  resting bp s  cholesterol  fasting blood sugar  \\\n",
       "0   40    1                2           140          289                    0   \n",
       "1   49    0                3           160          180                    0   \n",
       "2   37    1                2           130          283                    0   \n",
       "3   48    0                4           138          214                    0   \n",
       "4   54    1                3           150          195                    0   \n",
       "\n",
       "   resting ecg  max heart rate  exercise angina  oldpeak  ST slope  target  \n",
       "0            0             172                0      0.0         1       0  \n",
       "1            0             156                0      1.0         2       1  \n",
       "2            1              98                0      0.0         1       0  \n",
       "3            0             108                1      1.5         2       1  \n",
       "4            0             122                0      0.0         1       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'target':'outcome'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  chest pain type  resting bp s  cholesterol  fasting blood sugar  \\\n",
       "0   40    1                2           140          289                    0   \n",
       "1   49    0                3           160          180                    0   \n",
       "2   37    1                2           130          283                    0   \n",
       "3   48    0                4           138          214                    0   \n",
       "4   54    1                3           150          195                    0   \n",
       "\n",
       "   resting ecg  max heart rate  exercise angina  oldpeak  ST slope  outcome  \n",
       "0            0             172                0      0.0         1        0  \n",
       "1            0             156                0      1.0         2        1  \n",
       "2            1              98                0      0.0         1        0  \n",
       "3            0             108                1      1.5         2        1  \n",
       "4            0             122                0      0.0         1        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance:\n",
      "1 561\n",
      "0 629\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "zero = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['outcome'] == 0:\n",
    "        one+=1\n",
    "    else:\n",
    "        zero+=1\n",
    "        \n",
    "print(\"Class balance:\")\n",
    "print(\"1\",one)\n",
    "print(\"0\",zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.720168</td>\n",
       "      <td>0.763866</td>\n",
       "      <td>3.232773</td>\n",
       "      <td>132.153782</td>\n",
       "      <td>210.363866</td>\n",
       "      <td>0.213445</td>\n",
       "      <td>0.698319</td>\n",
       "      <td>139.732773</td>\n",
       "      <td>0.387395</td>\n",
       "      <td>0.922773</td>\n",
       "      <td>1.624370</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.358203</td>\n",
       "      <td>0.424884</td>\n",
       "      <td>0.935480</td>\n",
       "      <td>18.368823</td>\n",
       "      <td>101.420489</td>\n",
       "      <td>0.409912</td>\n",
       "      <td>0.870359</td>\n",
       "      <td>25.517636</td>\n",
       "      <td>0.487360</td>\n",
       "      <td>1.086337</td>\n",
       "      <td>0.610459</td>\n",
       "      <td>0.499393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>269.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex  chest pain type  resting bp s  cholesterol  \\\n",
       "count  1190.000000  1190.000000      1190.000000   1190.000000  1190.000000   \n",
       "mean     53.720168     0.763866         3.232773    132.153782   210.363866   \n",
       "std       9.358203     0.424884         0.935480     18.368823   101.420489   \n",
       "min      28.000000     0.000000         1.000000      0.000000     0.000000   \n",
       "25%      47.000000     1.000000         3.000000    120.000000   188.000000   \n",
       "50%      54.000000     1.000000         4.000000    130.000000   229.000000   \n",
       "75%      60.000000     1.000000         4.000000    140.000000   269.750000   \n",
       "max      77.000000     1.000000         4.000000    200.000000   603.000000   \n",
       "\n",
       "       fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "count          1190.000000  1190.000000     1190.000000      1190.000000   \n",
       "mean              0.213445     0.698319      139.732773         0.387395   \n",
       "std               0.409912     0.870359       25.517636         0.487360   \n",
       "min               0.000000     0.000000       60.000000         0.000000   \n",
       "25%               0.000000     0.000000      121.000000         0.000000   \n",
       "50%               0.000000     0.000000      140.500000         0.000000   \n",
       "75%               0.000000     2.000000      160.000000         1.000000   \n",
       "max               1.000000     2.000000      202.000000         1.000000   \n",
       "\n",
       "           oldpeak     ST slope      outcome  \n",
       "count  1190.000000  1190.000000  1190.000000  \n",
       "mean      0.922773     1.624370     0.528571  \n",
       "std       1.086337     0.610459     0.499393  \n",
       "min      -2.600000     0.000000     0.000000  \n",
       "25%       0.000000     1.000000     0.000000  \n",
       "50%       0.600000     2.000000     1.000000  \n",
       "75%       1.600000     2.000000     1.000000  \n",
       "max       6.200000     3.000000     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      0\n",
       "sex                    281\n",
       "chest pain type          0\n",
       "resting bp s             1\n",
       "cholesterol            172\n",
       "fasting blood sugar    936\n",
       "resting ecg            684\n",
       "max heart rate           0\n",
       "exercise angina        729\n",
       "oldpeak                455\n",
       "ST slope                 1\n",
       "outcome                561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df==0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1190 entries, 0 to 1189\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   age                  1190 non-null   int64  \n",
      " 1   sex                  1190 non-null   int64  \n",
      " 2   chest pain type      1190 non-null   int64  \n",
      " 3   resting bp s         1190 non-null   int64  \n",
      " 4   cholesterol          1190 non-null   int64  \n",
      " 5   fasting blood sugar  1190 non-null   int64  \n",
      " 6   resting ecg          1190 non-null   int64  \n",
      " 7   max heart rate       1190 non-null   int64  \n",
      " 8   exercise angina      1190 non-null   int64  \n",
      " 9   oldpeak              1190 non-null   float64\n",
      " 10  ST slope             1190 non-null   int64  \n",
      " 11  outcome              1190 non-null   int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 111.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate x and y and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('outcome', axis=1)\n",
    "y = df['outcome']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 0.01, 'gamma': 1, 'kernel': 'poly'}\n",
      "First round: {'C': 0.008, 'gamma': 1, 'kernel': 'poly'}\n",
      "Second round: {'C': 0.006, 'gamma': 1, 'kernel': 'poly'}\n",
      "Third round: {'C': 0.006, 'gamma': 1, 'kernel': 'poly'}\n",
      "Fourth round: {'C': 0.004, 'gamma': 0.9, 'kernel': 'poly'}\n",
      "Fifth round: {'C': 0.004, 'gamma': 0.9, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "svmparam = SVC()\n",
    "\n",
    "#Random values initial\n",
    "X_svc_train, X_svc_test, y_svc_train, y_svc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "param_grid = {'C': [0.01,0.1,1,10,100], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round optimizing\n",
    "param_grid = {'C': [0.008, 0.009, 0.01, 0.02, 0.03], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round optimizing\n",
    "param_grid = {'C': [0.006, 0.007, 0.008, 0.009, 0.01], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd Round optimizing\n",
    "param_grid = {'C': [0.004, 0.005, 0.006, 0.007, 0.008], 'gamma': [10,1,0.1,0.01,0.001,0.0001],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Third round:\", grid_search.best_params_)\n",
    "\n",
    "#4th Round optimizing\n",
    "param_grid = {'C': [0.004, 0.005, 0.006, 0.007, 0.008], 'gamma': [0.8, 0.9, 1, 2, 3],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Fourth round:\", grid_search.best_params_)\n",
    "\n",
    "#5th Round optimizing\n",
    "param_grid = {'C': [0.002, 0.003, 0.004, 0.005, 0.006], 'gamma': [0.8, 0.9, 1, 2, 3],'kernel': ['sigmoid', 'poly', 'linear']}\n",
    "grid_search = GridSearchCV(estimator = svmparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_svc_train, y_svc_train)\n",
    "print( \"Fifth round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8543417366946778\n",
      "Recall: 0.8702702702702703\n",
      "Precision 0.8518518518518519\n",
      "F1_Score: 0.8609625668449198\n",
      "AUC: 0.9020427404148337\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[144  28]\n",
      " [ 24 161]]\n"
     ]
    }
   ],
   "source": [
    "#Without hyperparametering\n",
    "#svc = SVC(probability=True)\n",
    "\n",
    "#Accuracy 0.8627450980392157\n",
    "#Recall: 0.9027027027027027\n",
    "#Precision 0.8434343434343434\n",
    "#F1_Score: 0.8720626631853785\n",
    "#AUC: 0.9242614707730987\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[141  31]\n",
    "# [ 18 167]]\n",
    "\n",
    "#With hyperparametering\n",
    "svc = SVC(probability=True, C=0.004, gamma=0.9, kernel='poly')\n",
    "\n",
    "svc.fit(X_svc_train, y_svc_train)\n",
    "y_svc_pred = svc.predict(X_svc_test)\n",
    "\n",
    "svc_score = svc.predict_proba(X_svc_test)[: ,1]\n",
    "\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "\n",
    "accuracy_score_svc = accuracy_score(y_svc_test, y_svc_pred)\n",
    "recall_score_svc = recall_score(y_svc_test, y_svc_pred)\n",
    "precision_score_svc = precision_score(y_svc_test, y_svc_pred)\n",
    "f1_score_svc = f1_score(y_svc_test, y_svc_pred)\n",
    "auc_svc = roc_auc_score(y_svc_test, svc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_svc)\n",
    "print(\"Recall:\", recall_score_svc)\n",
    "print(\"Precision\", precision_score_svc)\n",
    "print(\"F1_Score:\", f1_score_svc)\n",
    "print(\"AUC:\", auc_svc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_svc_test, y_svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "First round: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "dctparam = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "X_dtc_train, X_dtc_test, y_dtc_train, y_dtc_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [None, 1,2,3,4], 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1,2,3,4,5], 'criterion' : ['gini', 'entropy'], 'min_samples_split' : [1,2,3,4,5]}\n",
    "grid_search = GridSearchCV(estimator = dctparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_dtc_train, y_dtc_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#First round\n",
    "param_grid = {'max_depth': [None, 1,2,3,4], 'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1,2,3,4,5], 'criterion' : ['gini', 'entropy'], 'min_samples_split' : [1,2,3,4]}\n",
    "grid_search = GridSearchCV(estimator = dctparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_dtc_train, y_dtc_train)\n",
    "print( \"First round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8739495798319328\n",
      "Recall: 0.9135135135135135\n",
      "Precision 0.8535353535353535\n",
      "F1_Score: 0.8825065274151437\n",
      "AUC: 0.8724544311753615\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[143  29]\n",
      " [ 16 169]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "\n",
    "#dtc = DecisionTreeClassifier(random_state = RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.8739495798319328\n",
    "#Recall: 0.9135135135135135\n",
    "#Precision 0.8535353535353535\n",
    "#F1_Score: 0.8825065274151437\n",
    "#AUC: 0.8724544311753615\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[143  29]\n",
    "# [ 16 169]]\n",
    "\n",
    "\n",
    "#With Hyperparametering\n",
    "dtc = DecisionTreeClassifier(random_state = RANDOM_STATE, max_depth=None, max_features=None, criterion = 'gini',\n",
    "                             min_samples_leaf=1, min_samples_split=2)\n",
    "\n",
    "dtc.fit(X_dtc_train,y_dtc_train)\n",
    "y_dtc_pred = dtc.predict(X_dtc_test)\n",
    "\n",
    "dtc_score = dtc.predict_proba(X_dtc_test)[: , 1]\n",
    "\n",
    "accuracy_score_dtc = accuracy_score(y_dtc_test, y_dtc_pred)\n",
    "recall_score_dtc = recall_score(y_dtc_test, y_dtc_pred)\n",
    "precision_score_dtc = precision_score(y_dtc_test, y_dtc_pred)\n",
    "f1_score_dtc = f1_score(y_dtc_test, y_dtc_pred)\n",
    "auc_dtc = roc_auc_score(y_dtc_test, dtc_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_dtc)\n",
    "print(\"Recall:\", recall_score_dtc)\n",
    "print(\"Precision\", precision_score_dtc)\n",
    "print(\"F1_Score:\", f1_score_dtc)\n",
    "print(\"AUC:\", auc_dtc)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_dtc_test, y_dtc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'C': 0.1, 'max_iter': 250, 'penalty': 'l1', 'solver': 'saga'}\n",
      "First round: {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Second round: {'C': 0.1, 'max_iter': 20, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Third round: {'C': 0.2, 'max_iter': 20, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "lrparam = LogisticRegression()\n",
    "X_lr_train, X_lr_test, y_lr_train, y_lr_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "              'max_iter' : [250, 500, 1000, 1250, 1500], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "             'max_iter' : [50,100,150,200,250], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [10, 1, 0.1, 0.001, 0.0001], \n",
    "              'max_iter' : [20,30,40,50], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd round\n",
    "param_grid = {'penalty' : [None, 'l2','l1','elasticnet'], 'C' : [0.008, 0.009, 0.1, 0.2, 0.3], \n",
    "              'max_iter' : [20,30,40,50], 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "grid_search = GridSearchCV(estimator = lrparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_lr_train, y_lr_train)\n",
    "print( \"Third round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.834733893557423\n",
      "Recall: 0.8648648648648649\n",
      "Precision 0.8247422680412371\n",
      "F1_Score: 0.8443271767810027\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[138  34]\n",
      " [ 25 160]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#lr = LogisticRegression()\n",
    "\n",
    "#Accuracy 0.8319327731092437\n",
    "#Recall: 0.8594594594594595\n",
    "#Precision 0.8238341968911918\n",
    "#F1_Score: 0.8412698412698413\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[138  34]\n",
    "# [ 26 159]]\n",
    "\n",
    "#With Hyperparametering\n",
    "#Trying a new level for C (0.4, which gave a better result than 0.2)\n",
    "lr = LogisticRegression(C = 0.4, max_iter = 20, penalty = 'l1', solver = 'saga')\n",
    "\n",
    "lr.fit(X_lr_train,y_lr_train)\n",
    "y_lr_pred = lr.predict(X_lr_test)\n",
    "\n",
    "accuracy_score_lr = accuracy_score(y_lr_test, y_lr_pred)\n",
    "recall_score_lr = recall_score(y_lr_test, y_lr_pred)\n",
    "precision_score_lr = precision_score(y_lr_test, y_lr_pred)\n",
    "f1_score_lr = f1_score(y_lr_test, y_lr_pred)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_lr)\n",
    "print(\"Recall:\", recall_score_lr)\n",
    "print(\"Precision\", precision_score_lr)\n",
    "print(\"F1_Score:\", f1_score_lr)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_lr_test, y_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Initial: {'algorithm': 'auto', 'n_neighbors': 13, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knnparam = KNeighborsClassifier()\n",
    "X_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_neighbors': [2,3,4,5,6,7,8,9,10], 'weights': ['distance', 'uniform'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}\n",
    "grid_search = GridSearchCV(estimator = knnparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_knn_train, y_knn_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st round\n",
    "param_grid = {'n_neighbors': [10,11,12,13,14,15,16,17,18,19,20], 'weights': ['distance', 'uniform'],\n",
    "              'algorithm': ['auto','ball_tree', 'kd_tree', 'brute']}\n",
    "grid_search = GridSearchCV(estimator = knnparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_knn_train, y_knn_train)\n",
    "print( \"Initial:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9047619047619048\n",
      "Recall: 0.9243243243243243\n",
      "Precision 0.8952879581151832\n",
      "F1_Score: 0.9095744680851063\n",
      "AUC: 0.9530641106222502\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[152  20]\n",
      " [ 14 171]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "#knn = KNeighborsClassifier()\n",
    "\n",
    "#Accuracy 0.8571428571428571\n",
    "#Recall: 0.8702702702702703\n",
    "#Precision 0.8563829787234043\n",
    "#F1_Score: 0.8632707774798928\n",
    "#AUC: 0.9120993086109366\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[145  27]\n",
    "# [ 24 161]]\n",
    "\n",
    "#With Hyperparametering\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 13 , weights = 'distance', algorithm = 'auto')\n",
    "\n",
    "knn.fit(X_knn_train,y_knn_train)\n",
    "y_knn_pred = knn.predict(X_knn_test)\n",
    "\n",
    "knn_score = knn.predict_proba(X_knn_test)[: , 1]\n",
    "\n",
    "accuracy_score_knn = accuracy_score(y_knn_test, y_knn_pred)\n",
    "recall_score_knn = recall_score(y_knn_test, y_knn_pred)\n",
    "precision_score_knn = precision_score(y_knn_test, y_knn_pred)\n",
    "f1_score_knn = f1_score(y_knn_test, y_knn_pred)\n",
    "auc_knn = roc_auc_score(y_knn_test, knn_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_knn)\n",
    "print(\"Recall:\", recall_score_knn)\n",
    "print(\"Precision\", precision_score_knn)\n",
    "print(\"F1_Score:\", f1_score_knn)\n",
    "print(\"AUC:\", auc_knn)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_knn_test, y_knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "First round: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Second round: {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Third round: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 50}\n",
      "Fourth round: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Fifth round: {'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Sixth round: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Seventh round: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Eighth round: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Nineth round: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 150}\n",
      "Tenth round: {'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 300}\n",
      "Eleventh round: {'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 350}\n",
      "Twelfth round: {'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "#Optimizing parameters\n",
    "\n",
    "rfparam = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'max_depth': [1, 2, 3, 4], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [1,2,3,4], 'n_estimators' : [25, 50, 100, 150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round\n",
    "param_grid = {'max_depth': [3,4,5], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round\n",
    "param_grid = {'max_depth': [4,5,6], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Second round:\", grid_search.best_params_)\n",
    "\n",
    "#3rd Round\n",
    "param_grid = {'max_depth': [5,6,7], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Third round:\", grid_search.best_params_)\n",
    "\n",
    "#4th Round\n",
    "param_grid = {'max_depth': [6,7,8], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Fourth round:\", grid_search.best_params_)\n",
    "\n",
    "#5th Round\n",
    "param_grid = {'max_depth': [7,8,9], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Fifth round:\", grid_search.best_params_)\n",
    "\n",
    "#6th Round\n",
    "param_grid = {'max_depth': [8,9,10], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Sixth round:\", grid_search.best_params_)\n",
    "\n",
    "#7th Round\n",
    "param_grid = {'max_depth': [9,10,11], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Seventh round:\", grid_search.best_params_)\n",
    "\n",
    "#8th Round\n",
    "param_grid = {'max_depth': [9,10,11], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Eighth round:\", grid_search.best_params_)\n",
    "\n",
    "#9th Round\n",
    "param_grid = {'max_depth': [11,12,13], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [25,50,100,150]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Ninth round:\", grid_search.best_params_)\n",
    "\n",
    "#10th Round\n",
    "param_grid = {'max_depth': [11,12,13], 'min_samples_leaf': [1,2,3,4], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [150,200,250,300]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Tenth round:\", grid_search.best_params_)\n",
    "\n",
    "#11th Round\n",
    "param_grid = {'max_depth': [11,12,13], 'min_samples_leaf': [1,2,3], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [3,4,5], 'n_estimators' : [300,350,400,450]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Eleventh round:\", grid_search.best_params_)\n",
    "\n",
    "#12th Round\n",
    "param_grid = {'max_depth': [11,12,13], 'min_samples_leaf': [1,2,3], \n",
    "              'criterion' : ['gini', 'entropy'], \n",
    "              'min_samples_split' : [1,2,3,4], 'n_estimators' : [300,350,400,450]}\n",
    "grid_search = GridSearchCV(estimator = rfparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_rf_train, y_rf_train)\n",
    "print( \"Twelfth round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9187675070028011\n",
      "Recall: 0.9621621621621622\n",
      "Precision 0.89\n",
      "F1_Score: 0.9246753246753247\n",
      "AUC: 0.9538969201759899\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[150  22]\n",
      " [  7 178]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "\n",
    "#rf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.9159663865546218\n",
    "#Recall: 0.9567567567567568\n",
    "#Precision 0.8894472361809045\n",
    "#F1_Score: 0.9218749999999999\n",
    "#AUC: 0.9569767441860465\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[150  22]\n",
    "# [  8 177]]\n",
    "\n",
    "#With Hyperparametering\n",
    "rf = RandomForestClassifier(n_estimators = 350, random_state=RANDOM_STATE, \n",
    "                           min_samples_leaf=1, min_samples_split=3, max_depth=12, criterion = 'gini')\n",
    "\n",
    "rf.fit(X_rf_train, y_rf_train)\n",
    "y_rf_pred = rf.predict(X_rf_test)\n",
    "\n",
    "rf_score = rf.predict_proba(X_rf_test)[: , 1]\n",
    "\n",
    "accuracy_score_rf = accuracy_score(y_rf_test, y_rf_pred)\n",
    "recall_score_rf = recall_score(y_rf_test, y_rf_pred)\n",
    "precision_score_rf = precision_score(y_rf_test, y_rf_pred)\n",
    "f1_score_rf = f1_score(y_rf_test, y_rf_pred)\n",
    "auc_rf = roc_auc_score(y_rf_test, rf_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_rf)\n",
    "print(\"Recall:\", recall_score_rf)\n",
    "print(\"Precision\", precision_score_rf)\n",
    "print(\"F1_Score:\", f1_score_rf)\n",
    "print(\"AUC:\", auc_rf)\n",
    "print()\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_rf_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "First round: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Second round: {'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "abparam = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "X_ab_train, X_ab_test, y_ab_train, y_ab_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "#Random values initial\n",
    "param_grid = {'n_estimators': [50, 100, 150, 200, 250], 'learning_rate': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Initial:\", grid_search.best_params_)\n",
    "\n",
    "#1st Round optimizing\n",
    "param_grid = {'n_estimators': [25, 50, 100, 150, 200], 'learning_rate': [1,0.1,0.01,0.001,0.0001]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"First round:\", grid_search.best_params_)\n",
    "\n",
    "#2nd Round optimizing\n",
    "param_grid = {'n_estimators': [25, 50, 100, 150, 200], 'learning_rate': [0.08,0.09, 0.1, 0.2, 0.3]}\n",
    "grid_search = GridSearchCV(estimator = abparam, param_grid = param_grid, cv=3, n_jobs = -1)\n",
    "grid_search.fit(X_ab_train, y_ab_train)\n",
    "print( \"Second round:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8599439775910365\n",
      "Recall: 0.8810810810810811\n",
      "Precision 0.8534031413612565\n",
      "F1_Score: 0.8670212765957447\n",
      "AUC: 0.9143620364550598\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[144  28]\n",
      " [ 22 163]]\n"
     ]
    }
   ],
   "source": [
    "#Without Hyperparametering\n",
    "ab = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#Accuracy 0.865546218487395\n",
    "#Recall: 0.8810810810810811\n",
    "#Precision 0.8624338624338624\n",
    "#F1_Score: 0.8716577540106951\n",
    "#AUC: 0.9209302325581395\n",
    "\n",
    "#=== Confusion Matrix ===\n",
    "#[[146  26]\n",
    "# [ 22 163]]\n",
    "\n",
    "#With Hyperparametering\n",
    "ab = AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "\n",
    "ab.fit(X_ab_train, y_ab_train)\n",
    "y_ab_pred = ab.predict(X_ab_test)\n",
    "\n",
    "ab_score = ab.predict_proba(X_ab_test)[: , 1]\n",
    "\n",
    "accuracy_score_ab = accuracy_score(y_ab_test, y_ab_pred)\n",
    "recall_score_ab = recall_score(y_ab_test, y_ab_pred)\n",
    "precision_score_ab = precision_score(y_ab_test, y_ab_pred)\n",
    "f1_score_ab = f1_score(y_ab_test, y_ab_pred)\n",
    "auc_ab = roc_auc_score(y_ab_test, ab_score)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score_ab)\n",
    "print(\"Recall:\", recall_score_ab)\n",
    "print(\"Precision\", precision_score_ab)\n",
    "print(\"F1_Score:\", f1_score_ab)\n",
    "print(\"AUC:\", auc_ab)\n",
    "print()\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_ab_test, y_ab_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
